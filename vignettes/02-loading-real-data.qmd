---
title: "Loading data"
format: html
editor: source
---

```{r setup}
# Data generation for testing purposes
library(dplyr)
library(haven)
library(forcats)
library(readr)
library(arrow)
library(purrr)
library(data.table)
library(collapse)

```


```{r reload-data, eval=FALSE}
dta <-
  Sys.getenv("POVSPARK_DATA") |>
  file.path("ALL_final_vars", "ALL_final_vars.dta") |>
  haven::read_dta(n_max = 10e6)

dta |> readr::write_rds("data-temp/ALL_final_vars.rds")
```

```{r clean-save-data, eval=FALSE}
dta <- readr::read_rds("data-temp/ALL_final_vars.rds")
dta <- qDT(dta)

var_classes <- sapply(dta, class)
labelled_vars <- keep(var_classes, ~ "haven_labelled" %in% .x) |> names()
# labelled_vars <- labelled_vars[1:2]

# Modify 'labelled_vars' to convert to factors with "Missing" level for NAs
# Use data table syntax for efficiency and avoid copying the entire dataset multiple times
dta[,
  (labelled_vars) := lapply(.SD, function(x) {
    gc()
    haven::as_factor(x) |> forcats::fct_na_value_to_level("Missing")
  }),
  .SDcols = labelled_vars
]

# Sort the dataset by country and year
setorder(dta, code, year)

# Save data as parquet dataset groupping by country for faster loading
dta |>
  arrow::write_dataset(
    path = "data-testing/gmd-full",
    format = "parquet",
    partitioning = "code"
  )
```


## Simplifying data 

```{r simplify-data, eval=FALSE}
dta_0 <- open_dataset("data-testing/gmd-full")
dta_0 |> glimpse()

vars_focus <- c(
  "code",
  "year",
  "welfare",
  "weight_h",
  "weight_p",
  "cpi2021",
  "icp2021",
  "school",
  "educat4",
  "educat5",
  "educat7",
  "marital",
  "lstatus",
  "empstat",
  "industrycat4",
  "industrycat10",
  "cellphone",
  "computer",
  "electricity",
  "male",
  "urban"
)

dta_full <-
  dta_0 |>
  select(all_of(vars_focus)) |>
  filter(!code == "") |>
  mutate(
    welfppp = welfare / cpi2021 / icp2021 / 365
  ) |>
  filter(welfppp > 0, !is.na(welfppp)) |>
  mutate(
    welfppp = if_else(welfppp <= 0.28, 0.28, welfppp, welfppp)
  ) |>
  select(
    -welfare,
    -cpi2021,
    -icp2021
  ) |>
  collect() |>
  mutate(code = as_factor(code), year = as.integer(year)) |>
  qDT()

# based in each factor variable in dta_full, create a table disctionary of the levels with three columns: # variable name, level value, level label
dta_dic <- list()
for (var in names(dta_full)) {
  if (is.factor(dta_full[[var]])) {
    levels_var <- levels(dta_full[[var]])
    dta_dic[[var]] <- data.frame(
      variable = var,
      value = seq_along(levels_var),
      label = levels_var
    )
  }
}

dta_dic <- bind_rows(dta_dic)
dta_dic |> readr::write_csv("data-testing/gmd-simple-dic.csv")

# Convert each factor variable to integer using collapse and data.table
factor_vars <- names(dta_full)[sapply(dta_full, is.factor)]
dta_full[, (factor_vars) := lapply(.SD, as.integer), .SDcols = factor_vars]

# Sort data by country and year and welfppp
setorder(dta_full, code, year, welfppp)

# Check if there are any NA
sapply(dta_full, function(x) sum(is.na(x)))

# Save simplified data
dta_full |>
  arrow::write_dataset(
    path = "data-testing/gmd-simple",
    format = "parquet",
    partitioning = "code"
  )
```


## Resaving data in duckdb format

```{r duck-db-setup, eval=FALSE}
library(arrow)
library(dplyr, warn.conflicts = FALSE)
library(DBI)
library(duckdb)
library(dbplyr)
library(duckplyr)
library(here)
library(glue)


pkt_fldr <- here("data-testing")
duck_fldr <- here("data-testing-duck")
dir.create(duck_fldr)


from_file <- list.dirs(pkt_fldr, recursive = FALSE, full.names = F) |> sort()
from_pkt <- from_file[[2]]

# duck_dr <- duckdb(file.path("data-testing-duck", paste(from_pkt, ".duckdb")))
# con <- dbConnect(duck_dr)

# dbGetQuery(conn = con, "SELECT current_setting('threads') AS threads")
# dbGetQuery(conn = con, "SELECT current_setting('memory_limit') AS memlimit")

# tbl_nm <- from_pkt
pqt_path <- file.path(pkt_fldr, from_pkt, "**/*.parquet")

reloar_q <- "
DROP TABLE IF EXISTS dta;
CREATE TABLE dta AS SELECT * FROM read_parquet('{pqt_path}');
ANALYZE dta;
VACUUM;
"

from_file |>
  purrr::walk(
    ~ {
      from_pkt <- .x
      duck_dr <- duckdb(file.path("data-testing-duck", paste0(from_pkt, ".duckdb")))
      con <- dbConnect(duck_dr)
      tbl_nm <- from_pkt
      pqt_path <- file.path(pkt_fldr, from_pkt, "**/*.parquet")

      dbExecute(con, statement = glue(reloar_q))
      dbDisconnect(con, shutdown = TRUE)
    }
  )
```